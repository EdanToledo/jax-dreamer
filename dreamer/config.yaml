defaults:
  # Train Script
  log_dir: results
  seed: 0
  task: pendulum.swingup
  time_limit: 1000
  action_repeat: 2
  steps: 1e6
  training_steps_per_epoch: 2.5e4
  evaluation_steps_per_epoch: 1e4
  prefill: 5000
  train_every: 1000
  update_steps: 100
  replay: {capacity: 1000, batch: 32, sequence_length: 50}
  jit: True
  render_episodes: 1
  evaluate_model: True

  # World Model
  rssm: {hidden: 200, deterministic_size: 200, stochastic_size: 32}
  model_opt: {lr: 3e-4, eps: 1e-5, clip: 100}
  encoder: {depth: 32, kernels: [4, 4, 4, 4]}
  decoder: {depth: 32, kernels: [5, 5, 6, 6]}
  reward: {output_sizes: [400, 400]}
  terminal: {output_sizes: [400, 400]}
  free_kl: 3.0
  kl_scale: 1.0

  # Actor-Critic
  actor: {output_sizes: [400, 400, 400, 400], min_stddev: 1e-4}
  critic: {output_sizes: [400, 400, 400, 400]}
  actor_opt: {lr: 3e-4, eps: 1e-5, clip: 100}
  critic_opt: {lr: 3e-4, eps: 1e-5, clip: 100}
  discount: 0.99
  lambda_: 0.95
  imag_horizon: 15

debug:
  jit: False
  time_limit: 100
  training_steps_per_epoch: 200
  evaluation_steps_per_epoch: 100
  prefill: 100
  train_every: 100
  update_steps: 2
  render_episodes: 0
  replay: {capacity: 10, batch: 5, sequence_length: 12}